<div class="row">
    <h2>Projects</h2>
    <hr>


<table width="100%" align="left" border="0" cellspacing="0" cellpadding="20" style="border-collapse:separate; border-spacing:25px;">
	<tbody style="text-align:left;">

        
    <tr>
		<td valign="top" width="30%">
			 <img src="/static/img/spectro.png" width="320" height="auto">
		</td>
		<td valign="top" width="80%">
			<b>Low cost, Portable LED-Spectrophotometer for the Detection of Nitrite in Urine</b>
      <br> (Accepted at IEEE UPCON 2019) <br> 
			<b>Sauranil Debarshi</b>,
			<a href="https://scholar.google.co.in/citations?user=YEbRuroAAAAJ&hl=en">Mohd Mansoor Khan</a>
			<br><br>
			<p> Developed a portable spectrophotometer that uses a UV-LED, a Si-pin photodiode
			and a microcontroller to detect and warn users of the presence of nitrite in urine, in real-time. The prototype can also be configured to detect glucose and blood.
		</td>
	</tr>
	

    <tr>
		<td valign="top" width="30%">
	    <img src="/static/img/person.png" width="330" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>UAV-based Person Re-Identification and Dynamic Image Routing using Wireless Mesh Networking</b>
			<br><br>
      <b>Sauranil Debarshi</b>,
			<a>Neelabhro Roy</a>,
			<a href="https://scholar.google.com/citations?user=6HHe0yEAAAAJ&hl=en">P.B. Sujit</a>, 
			<a href="https://scholar.google.co.in/citations?user=aPDRgKAAAAAJ&hl=en">A V Subramanyam</a>
			<br><br>
			<p>We propose a system wherein we explore on-board  re-identification  of  persons  using  cameras  mounted on Unmanned Aerial Vehicles (UAVs).  The camera images are dynamically shared between multiple UAVs by virtue of wireless mesh networking, also making use of the Robot Operating System (ROS) for on-ground control of the UAVs from a control station, facilitating the exchange of images between them.</p>
			
			<a href="https://github.com/sauranildebs/UAV-based-Person-Re-Identification-and-Dynamic-Image-Routing-using-WMNs"><b>Code</b></a>
		</td>
	</tr>
	

    <tr>
		<td valign="top" width="30%">
			 <img src="/static/img/NIWT_teaser.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Choose Your Neuron: Incorporating Domain Knowledge into Deep Networks through Neuron Importance</b>
      <br> (Presented in ECCV'18) <br> 
      <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju*</b>,
			<a href="https://about.me/chattopadhyayprithvijit">Prithviraj Chattopadhyay*</a>, 
			<a href="https://sites.google.com/site/mhelhoseiny/">Mohamed Elhoseiny</a>,
			<a href="">Tilak Sharma</a>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,
			<a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>,
			<a href="https://www.cc.gatech.edu/~slee3191/">Stefen Lee</a>,
			<br>
			<a href="https://arxiv.org/abs/1808.02861">Arxiv Paper: https://arxiv.org/abs/1808.02861</a> 
			<br>
			<br>
		</td>
	</tr>
	

	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/Grad-CAM_teaser.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization</b>
      <br> (Presented in ICCV'17 and accepted to IJCV) <br> 
      <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="mcogswell.io">Michael Cogswell</a>,  
      <a href="http://abhishekdas.com/about/">Abhishek Das</a>, 
			<a href="http://ramakrishnavedantam928.github.io/">Ramakrishna Vedantam</a>, 
			<a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>,
			<br>
			<a href="https://arxiv.org/abs/1610.02391">Arxiv Paper: https://arxiv.org/abs/1610.02391</a> 
			[<a href="https://github.com/ramprs/grad-cam/">Code</a>]
			[<a href="http://gradcam.cloudcv.org/">Live Demo</a>]
			<br>
			<br>
		</td>
	</tr>
	
	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/dbs_teaser.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Diverse Beam Search: Diverse Decoding from Neural Sequence Models</b>
      <br> (Presented in AAAI'18) <br> 
			<br> 
			<a href="https://computing.ece.vt.edu/~ashwinkv/">Ashwin Kalyan</a>, 
			<a href="mcogswell.io">Michael Cogswell</a>, 
      <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="https://computing.ece.vt.edu/~sunqing/">Qing Sun</a>,
			<a href="https://www.cc.gatech.edu/~slee3191/">Stefen Lee</a>,
			<a href="https://www.cs.indiana.edu/~djcran/">David Crandal</a>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>
            <br>
			<a href="https://arxiv.org/abs/1610.02424">Arxiv Paper: https://arxiv.org/abs/1610.02424</a> 
            <br>
			[<a href="https://github.com/ashwinkalyan/dbs">Code</a>]
    		<br>
			<br>
			</td>
	</tr>
	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/counting_teaser.PNG" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>Counting Everyday Objects in Everyday Scenes</b>
			<br> (Spotlight talk at CVPR'17) <br> 
			<a href="https://about.me/chattopadhyayprithvijit">Prithviraj Chattopadhyay*</a>, 
			<a href="http://vrama91.github.io/">Ramakrishna Vedantam*</a>,
            <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="https://www.cc.gatech.edu/~dbatra/">Dhruv Batra</a>, 
			<a href="https://www.cc.gatech.edu/~parikh/">Devi Parikh</a>
			<br>
			[<a href= "https://arxiv.org/abs/1604.03505"> ArXiv paper: https://arxiv.org/abs/1604.03505</a>] 
			<br>
			<br>
		</td>
	</tr>

<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/paintbrush_teaser.jpg" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>The Semantic Paintbrush: Interactive 3D Mapping and Recognition in Large Outdoor Spaces</b>
			<br> (Oral at CHI'15) <br> 
			<a href="http://www.miksik.co.uk/">Ondrej Miksik</a>,
			<a href="http://stanford.edu/~vibhavv/index.html">Vibhav Vineet</a>,
			<a href="http://morten.lidegaard.net/">Morten Lidegaard</a>,
            <b href="http://ramprs.github.io">Ramprasaath R. Selvaraju</b>,
			<a href="http://graphics.stanford.edu/~niessner/publications.html">Matthias Nießner</a>,
			<a href="http://www.cs.ox.ac.uk/people/stuart.golodetz/">Stuart Golodetz</a>,
			<a href="http://www.ndcn.ox.ac.uk/departments/DCN/team/research-scientists/stephen-hicks">Stephen L. Hicks</a>,
			<a href="http://www.technicolor.com/en/patrick-perez">Patrick Pérez</a>,
			<a href="http://research.microsoft.com/en-us/people/shahrami/">Shahram Izadi</a>,
			<a href="http://www.robots.ox.ac.uk/~tvg/people.php">Philip H. S. Torr</a>
			[<a href= "http://www.graphics.stanford.edu/~niessner/papers/2015/2paintbrush/miksik2015chi.pdf"> Paper</a>] 
			<br>
		</td>
	</tr>


	<tr>
		<td valign="top" width="30%">
			 <img src="/static/img/blindfold.png" width="250" height="auto">
		</td>
		<td valign="top" width="70%">
			<b>BlindFind: Wearable Computer-Vision Rig for the Visually Impaired</b>
			<br> 
			<a href="">Eduardo Schmidt</a>,
            <a href="https://ramprs.github.io"><b>Ramprasaath R Selvaraju</b></a>,
			<a href="">Joshua</a>,
			<a href="">Brandon</a>,
			<a href="">Krishna</a>,
			<a href="">Brian</a>,
			<a href="">Fırat Kalaycılar</a>,
			<a href="https://vivo.brown.edu/display/bkimia">Benjamin Kimia</a>
		</td>
	</tr>

</tbody></table>

<!--
    <div class="row">
      <div class="col-sm-12">
        <h3 class="content_heading"><a target="_blank" href="http://gradcam.cloudcv.org">Gradient-weighted Class Activation Mapping (Grad-CAM)</a> Demo</h3>
        <br>
        <p>Gradient-weighted Class Activation Mapping (Grad-CAM) is a novel class-discriminative localization technique, that can be used to make CNN based models interpretable. Grad-CAM highlights regions of the image the VQA model looks at while making predictions. Given an image and a caption or question about that image, the model shows where it looked while doing prediction.</p>
        <a class="github-button btn" href="https://github.com/cloud-cv/grad-cam" data-size="large" data-show-count="false" aria-label="cloud-cv/grad-cam on GitHub">Code</a>
        <a class="github-button" href="https://github.com/cloud-cv/grad-cam" data-icon="octicon-star" data-size="large" data-show-count="true" aria-label="Star cloud-cv/grad-cam on GitHub">Star</a>
        <a class="github-button" href="https://github.com/cloud-cv/grad-cam/fork" data-icon="octicon-repo-forked" data-size="large" data-show-count="true" aria-label="Fork cloud-cv/grad-cam on GitHub">Fork</a>
      </div>
    </div>
    <br>
    <div class="row" align="center">
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/vqa">Grad-CAM VQA Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/vqa"><img src="/static/img/gcam_vqa.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/classification">Grad-CAM Classification Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/classification"><img src="/static/img/gcam_classification.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4><a href="http://gradcam.cloudcv.org/captioning">Grad-CAM Captioning Demo</a></h4>
        <a href="http://gradcam.cloudcv.org/captioning"><img src="/static/img/gcam_captioning.gif" width="100%"></a>
      </div>
      <div class="col-sm-6">
        <h4>Grad-CAM Demo Video</h4>
        <iframe width="100%" height="315" src="https://www.youtube.com/embed/COjUB9Izk6E?start=29" frameborder="0" allowfullscreen></iframe>
      </div>
    </div>

    <hr>
-->


</div>
